{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR8S7iGS-liA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53834720-fa78-4a37-e28d-daf4b462b22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/content/EmotionData.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/EmotionData.zip or\n",
            "        /content/EmotionData.zip.zip, and cannot find /content/EmotionData.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "# # # Unzipping the uploaded file\n",
        "!unzip -q /content/EmotionData.zip -d /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmbPurIU-lR8"
      },
      "outputs": [],
      "source": [
        "# # # Check contents of the unzipped folder\n",
        "!ls /content/EmotionData\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0amyBtE4l5b"
      },
      "source": [
        "## Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlelNtNs4l5s"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsMcUvqT4l5y"
      },
      "source": [
        "## The porject is based on 2 levels\n",
        "\n",
        "- level 1 : To preprocess and train catagories (e.g Negative, Neutral and Positive\n",
        "- level 2 : Further classify the emotions into the specific catagories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSYOUx0R4l5z"
      },
      "source": [
        "## Data Preprocessing of Level1 Catagories\n",
        "\n",
        " - Negative\n",
        " - Neutral\n",
        " - Positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOX9woyJ4l50",
        "outputId": "886c3d03-9560-45e6-a40a-dd8b7575ad39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22968 images belonging to 3 classes.\n",
            "Found 5741 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Define base directory path\n",
        "base_dir = '/content/EmotionData/'\n",
        "\n",
        "# Data augmentation and preprocessing for training\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Load training and validation datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Training set\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'  # Validation set\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edbi2iXZ4l57"
      },
      "source": [
        "## Build & Train the Model for Catagories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxpQAgnf4l59",
        "outputId": "c2ae21c2-4097-4426-b12a-057eb7869562"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Define the CNN model for Level 1 classification\n",
        "model_level1 = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztthx_my4l6A"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model_level1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUd0gvvg4l6F",
        "outputId": "aed6787c-c3cc-4802-a9c3-7738adb75d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 851ms/step - accuracy: 0.4797 - loss: 1.0828 - val_accuracy: 0.5731 - val_loss: 0.9274\n",
            "Epoch 2/5\n",
            "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 858ms/step - accuracy: 0.5963 - loss: 0.8725 - val_accuracy: 0.5861 - val_loss: 0.8830\n",
            "Epoch 3/5\n",
            "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 837ms/step - accuracy: 0.6628 - loss: 0.7529 - val_accuracy: 0.6231 - val_loss: 0.8354\n",
            "Epoch 4/5\n",
            "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 830ms/step - accuracy: 0.7291 - loss: 0.6263 - val_accuracy: 0.6224 - val_loss: 0.8831\n",
            "Epoch 5/5\n",
            "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 830ms/step - accuracy: 0.8188 - loss: 0.4453 - val_accuracy: 0.6041 - val_loss: 1.0765\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "history_level1 = model_level1.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h81J7zov4l6H"
      },
      "source": [
        "## Evaluate the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zUhSxJaa4l6J",
        "outputId": "23378c4d-782b-444d-e270-3e08118d67f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 230ms/step - accuracy: 0.6084 - loss: 1.0863\n",
            "Validation Accuracy: 60.41%\n"
          ]
        }
      ],
      "source": [
        " # Evaluate model performance\n",
        "val_loss, val_acc = model_level1.evaluate(validation_generator)\n",
        "print(f'Validation Accuracy: {val_acc * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JmSym0ns4l6K",
        "outputId": "68e5ab27-552f-400b-960a-26d5aff88006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[8.6699259e-01, 5.5970624e-03, 1.2741011e-01],\n",
              "       [8.6116290e-01, 6.6049121e-02, 7.2787926e-02],\n",
              "       [5.3615016e-01, 2.9819025e-02, 4.3403068e-01],\n",
              "       ...,\n",
              "       [2.7150540e-03, 9.2288232e-05, 9.9719268e-01],\n",
              "       [5.2724892e-01, 2.3898438e-01, 2.3376665e-01],\n",
              "       [6.8142807e-01, 3.1811678e-01, 4.5512052e-04]], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display confusion matrix and classification report\n",
        "Y_pred = model_level1.predict(validation_generator)\n",
        "Y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XOf3sYh34l6L",
        "outputId": "22876274-26b6-43ad-efb1-cc423d0c121b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[1402  402  867]\n",
            " [ 521  159  313]\n",
            " [1067  319  691]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.47      0.52      0.50      2671\n",
            "     Neutral       0.18      0.16      0.17       993\n",
            "    Positive       0.37      0.33      0.35      2077\n",
            "\n",
            "    accuracy                           0.39      5741\n",
            "   macro avg       0.34      0.34      0.34      5741\n",
            "weighted avg       0.38      0.39      0.39      5741\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "\n",
        "print('Classification Report')\n",
        "target_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnMxFG744l6N"
      },
      "source": [
        "## Data Preprocessing for Level 2\n",
        "\n",
        " - Subcatagories of Level1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pyBqZVEa4l6O",
        "outputId": "1c5fc958-da8b-44b9-f86c-92e44f3188c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8309 images belonging to 2 classes.\n",
            "Found 2077 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Define paths to Level 2 Positive dataset\n",
        "positive_dir = '/content/EmotionData/Positive/'\n",
        "\n",
        "train_datagen_positive = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator_positive = train_datagen_positive.flow_from_directory(\n",
        "    positive_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator_positive = train_datagen_positive.flow_from_directory(\n",
        "    positive_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2hGmqqVQ4l6T",
        "outputId": "4606a7d8-9571-4d26-e64d-9515a160666c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10687 images belonging to 4 classes.\n",
            "Found 2671 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "# Define paths to Level 2 Negative dataset\n",
        "negative_dir = '/content/EmotionData/Negative/'\n",
        "\n",
        "train_datagen_negative = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_generator_negative = train_datagen_negative.flow_from_directory(\n",
        "    negative_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator_negative = train_datagen_negative.flow_from_directory(\n",
        "    negative_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smNYvVvL4l6d"
      },
      "source": [
        "## Build and Train the Level 2 Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xRH1BnHv4l6f",
        "outputId": "e92c061d-2399-4d2b-fd55-d19f22c1dc7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 818ms/step - accuracy: 0.7434 - loss: 0.5630 - val_accuracy: 0.8002 - val_loss: 0.4281\n",
            "Epoch 2/5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 796ms/step - accuracy: 0.8609 - loss: 0.3424 - val_accuracy: 0.8209 - val_loss: 0.4160\n",
            "Epoch 3/5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 793ms/step - accuracy: 0.8978 - loss: 0.2531 - val_accuracy: 0.8710 - val_loss: 0.3229\n",
            "Epoch 4/5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 793ms/step - accuracy: 0.9284 - loss: 0.1812 - val_accuracy: 0.8652 - val_loss: 0.3476\n",
            "Epoch 5/5\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 793ms/step - accuracy: 0.9590 - loss: 0.1178 - val_accuracy: 0.8739 - val_loss: 0.4371\n"
          ]
        }
      ],
      "source": [
        "# Define the CNN model for Positive Emotion Classification (Level 2)\n",
        "model_positive = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_positive.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_positive = model_positive.fit(\n",
        "    train_generator_positive,\n",
        "    validation_data=validation_generator_positive,\n",
        "    epochs=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "N1inOjhJ4l6j",
        "outputId": "3d1698be-db52-44cd-fca0-69731baae8db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 797ms/step - accuracy: 0.3667 - loss: 1.4393 - val_accuracy: 0.4478 - val_loss: 1.1590\n",
            "Epoch 2/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 809ms/step - accuracy: 0.4821 - loss: 1.1039 - val_accuracy: 0.4747 - val_loss: 1.1134\n",
            "Epoch 3/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 805ms/step - accuracy: 0.5600 - loss: 0.9829 - val_accuracy: 0.4714 - val_loss: 1.1332\n",
            "Epoch 4/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 803ms/step - accuracy: 0.6311 - loss: 0.8318 - val_accuracy: 0.4826 - val_loss: 1.1749\n",
            "Epoch 5/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 802ms/step - accuracy: 0.7535 - loss: 0.6113 - val_accuracy: 0.4788 - val_loss: 1.4586\n"
          ]
        }
      ],
      "source": [
        "# Define the CNN model for Negative Emotion Classification (Level 2)\n",
        "model_negative = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_negative.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_negative = model_negative.fit(\n",
        "    train_generator_negative,\n",
        "    validation_data=validation_generator_negative,\n",
        "    epochs=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Tguz6Qas4l6o"
      },
      "outputs": [],
      "source": [
        "def hierarchical_emotion_classification(image):\n",
        "    # Step 1: Level 1 classification\n",
        "    level1_pred = model_level1.predict(image)\n",
        "    level1_class = np.argmax(level1_pred)\n",
        "\n",
        "    if level1_class == 2:  # Positive\n",
        "        # Step 2: Classify into Happy or Surprised\n",
        "        level2_pred = model_positive.predict(image)\n",
        "        emotion = 'Happy' if np.argmax(level2_pred) == 0 else 'Surprised'\n",
        "\n",
        "    elif level1_class == 0:  # Negative\n",
        "        # Step 2: Classify into Angry, Sad, Disgusted, Fearful\n",
        "        level2_pred = model_negative.predict(image)\n",
        "        emotion_labels = ['Angry', 'Sad', 'Disgusted', 'Fearful']\n",
        "        emotion = emotion_labels[np.argmax(level2_pred)]\n",
        "\n",
        "    else:\n",
        "        # Neutral emotion\n",
        "        emotion = 'Neutral'\n",
        "\n",
        "    return emotion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nKvySdHY4l6p"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the test image\n",
        "def load_image(img_path):\n",
        "    # Load the image with target size\n",
        "    img = image.load_img(img_path, target_size=(128, 128))\n",
        "    # Convert the image to an array\n",
        "    img_array = image.img_to_array(img)\n",
        "    # Reshape and normalize the image array\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Shape becomes (1, 128, 128, 3)\n",
        "    img_array /= 255.  # Rescale pixel values\n",
        "    return img_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qYk-nYEF4l6r",
        "outputId": "b35eeae6-f5f3-4064-9a35-b32648762239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "Image: /content/EmotionData/Negative/Disgusted/im10.png | Predicted Emotion: Angry\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Image: /content/EmotionData/Negative/Fearful/im1000.png | Predicted Emotion: Fearful\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Image: /content/EmotionData/Negative/Sad/im1001.png | Predicted Emotion: Disgusted\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Image: /content/EmotionData/Negative/Angry/im1002.png | Predicted Emotion: Neutral\n"
          ]
        }
      ],
      "source": [
        "# List of test image paths\n",
        "test_images = ['/content/EmotionData/Negative/Disgusted/im10.png', '/content/EmotionData/Negative/Fearful/im1000.png','/content/EmotionData/Negative/Sad/im1001.png','/content/EmotionData/Negative/Angry/im1002.png']\n",
        "\n",
        "# Iterate over the test images\n",
        "for img_path in test_images:\n",
        "    # Load and preprocess the image\n",
        "    img = load_image(img_path)\n",
        "\n",
        "    # Predict emotion\n",
        "    emotion = hierarchical_emotion_classification(img)\n",
        "\n",
        "    # Print the result\n",
        "    print(f'Image: {img_path} | Predicted Emotion: {emotion}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "drOyYdFA4l6s",
        "outputId": "12fb015e-86f4-4c44-d8bf-8900d6757ded"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# After training the model for positive emotions (happy, surprised)\n",
        "model_positive.save('positive_emotion_classifier.h5')\n",
        "# After training the model for negative emotions (sad, angry, fearful, etc.)\n",
        "model_negative.save('negative_emotion_classifier.h5')\n",
        "#\n",
        "model_level1.save('level1_emotion_classifier.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gbeugPMMOjJH",
        "outputId": "3183aa3a-8aee-4973-ae83-589c6dd24c28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.32.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.5)\n",
            "Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht2oP7r2WIiO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from flask import Flask, request, jsonify\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from flask_ngrok import run_with_ngrok  # Import ngrok integration\n",
        "\n",
        "# Load the saved models (adjust paths as needed)\n",
        "model_level1 = tf.keras.models.load_model('level1_emotion_classifier.h5')\n",
        "model_positive = tf.keras.models.load_model('positive_emotion_classifier.h5')\n",
        "model_negative = tf.keras.models.load_model('negative_emotion_classifier.h5')\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when running the app\n",
        "\n",
        "# Preprocessing function for images\n",
        "def preprocess_image(img):\n",
        "    img = img.resize((224, 224))  # Resize to the input size expected by your model\n",
        "    img = np.array(img)\n",
        "    img = img.astype('float32') / 255.0  # Normalize image\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    return img\n",
        "\n",
        "# Hierarchical emotion classification\n",
        "def classify_emotion(image):\n",
        "    # Step 1: Use level 1 classifier to distinguish between positive and negative\n",
        "    level1_prediction = model_level1.predict(image)\n",
        "    level1_label = np.argmax(level1_prediction)  # 0 for negative, 1 for positive\n",
        "\n",
        "    if level1_label == 1:\n",
        "        # Positive emotions (happy, surprised)\n",
        "        prediction = model_positive.predict(image)\n",
        "        labels = ['happy', 'surprised']\n",
        "    else:\n",
        "        # Negative emotions (sad, angry, fearful)\n",
        "        prediction = model_negative.predict(image)\n",
        "        labels = ['sad', 'angry', 'fearful']\n",
        "\n",
        "    predicted_label = labels[np.argmax(prediction)]\n",
        "    return predicted_label\n",
        "\n",
        "# Endpoint to classify emotion\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({'error': 'No file provided'}), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "\n",
        "    if file.filename == '':\n",
        "        return jsonify({'error': 'No file selected'}), 400\n",
        "\n",
        "    try:\n",
        "        img = Image.open(file)\n",
        "        processed_image = preprocess_image(img)\n",
        "\n",
        "        # Classify emotion hierarchically\n",
        "        predicted_emotion = classify_emotion(processed_image)\n",
        "\n",
        "        return jsonify({'emotion': predicted_emotion})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "# Main function to run the Flask app\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2xstqqTWQ-i"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5670154,
          "sourceId": 9353606,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30761,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}